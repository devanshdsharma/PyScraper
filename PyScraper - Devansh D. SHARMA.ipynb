{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WebScraping Project using Python\n",
    "\n",
    "\n",
    "_Source_ :  DM Automobiles' website(The website hosts listings for car re-sales.)\n",
    "\n",
    "_Resources Used_: Jupyter Notebooks(for Python), Beautiful Soup Library(for HTML parsing)\n",
    "\n",
    "_Objective & Approach_ : The approch behind executing this project has been to use python to scrape data of the source url and to provide the user with a csv containing the crucial data hosted by the website, viz The Make, Model, and Prices of the cars. Care has been taken to ensure the usability of the csv generated so that, the CSV is ready for analysis of the elements inside it. This includes removing irrelevant whitespaces and representing the data is in a access friendly format.\n",
    "\n",
    "_CSV Reommendations_ : To ensure best results, The recommended delimiter is \" , \".\n",
    "    The Decimal and Thousandths place separator must be set to standard EU currency format. ( example 41,900 €)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🏁\n",
    "# 🚗🚙🚓🚚🚌🚕🚛🚙🚗\n",
    "# 🏁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests # sedning requests to the URL\n",
    "from bs4 import BeautifulSoup as bs # #Python parsing library for HTML\n",
    "import os #for OS operations\n",
    "import re # for removing whitespace from before the prices\n",
    "import csv #for csv operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source = requests.get('https://pros.lacentrale.fr/C018357/?pro_only=0?pro_only=0&fromLC=true&fromLCHeader=true&max=100').text\n",
    "soup = bs(source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = open('dataExport.csv', 'w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow(['Make', 'Model', 'Prices'])\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#gives us the make and model of all cars\n",
    "'''The general approach has been to visually see where these elements are located using browser's web inspecting tools\n",
    "and then to grab the tag of the required element and call teh .text method on it to get all the text.\n",
    "After grabbing the text I sliced text accordingly to separate the make and modele of the car and then append all this data\n",
    "unto their dedicted lists'''\n",
    "import string\n",
    "make_Names = []\n",
    "model_Names= []\n",
    "Prices_Cars = []\n",
    "for var1 in soup.find_all('h3', class_ = 'brandModelTitle'):\n",
    "    car_Names = var1.text\n",
    "    test_Split = car_Names.split(\"\\n\")\n",
    "    full_Names = test_Split[1:3]\n",
    "    make = test_Split[1:2]\n",
    "    model = test_Split[2:3]\n",
    "    make_Names.append(make) \n",
    "    model_Names.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives the prices of all cars\n",
    "'''Utilizes similar approch used to grab the names, here we target a different class where the price lies.\n",
    "I also removed white spaces that ensures usefullness of the generated Prices, subsequently the CSV. '''\n",
    "for Prices in soup.find_all('span', class_ = 'f20 bold fieldPrice'):\n",
    "    Prices = Prices.span.text\n",
    "    Prices = re.sub(\"^\\s+|\\s+$\", \"\",Prices, flags=re.UNICODE) # removing whitespace before the prices\n",
    "    Prices_Cars.append(Prices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = open('dataExport.csv', 'a', newline='') # newline='' used to avoid generation of blank rows in the generated csv  \n",
    "csv_writer = csv.writer(csv_file)\n",
    "i = 0\n",
    "while i < len(Prices_Cars):\n",
    "    csv_writer.writerow([*make_Names[i], *model_Names[i], Prices_Cars[i]])  \n",
    "    # \" * \" used to unpack make_names, model_Names, remove the nested list\n",
    "    i = i + 1\n",
    "\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Uncomment _pwd_ to find the directory of the generated CSV'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pwd\n",
    "'''Uncomment _pwd_ to find the directory of the generated CSV'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🏁\n",
    "#       🚗  🚙  🚚 🚗 🚌  🚕  🚛  🚙  🚗\n",
    "# 🏁"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
